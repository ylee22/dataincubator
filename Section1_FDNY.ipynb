{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv('Incidents_Responded_to_by_Fire_Companies.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IM_INCIDENT_KEY', 'FIRE_BOX', 'INCIDENT_TYPE_DESC',\n",
       "       'INCIDENT_DATE_TIME', 'ARRIVAL_DATE_TIME', 'UNITS_ONSCENE',\n",
       "       'LAST_UNIT_CLEARED_DATE_TIME', 'HIGHEST_LEVEL_DESC',\n",
       "       'TOTAL_INCIDENT_DURATION', 'ACTION_TAKEN1_DESC', 'ACTION_TAKEN2_DESC',\n",
       "       'ACTION_TAKEN3_DESC', 'PROPERTY_USE_DESC', 'STREET_HIGHWAY', 'ZIP_CODE',\n",
       "       'BOROUGH_DESC', 'FLOOR', 'CO_DETECTOR_PRESENT_DESC',\n",
       "       'FIRE_ORIGIN_BELOW_GRADE_FLAG', 'STORY_FIRE_ORIGIN_COUNT',\n",
       "       'FIRE_SPREAD_DESC', 'DETECTOR_PRESENCE_DESC', 'AES_PRESENCE_DESC',\n",
       "       'STANDPIPE_SYS_PRESENT_FLAG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the column descriptions\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                               2277779\n",
       "unique                                  182\n",
       "top       300 - Rescue, EMS incident, other\n",
       "freq                                 823378\n",
       "Name: INCIDENT_TYPE_DESC, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1: what is the most common type of incident?\n",
    "# check the column incident type description to get the most common type\n",
    "df.INCIDENT_TYPE_DESC.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3614828304238471"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1: What proportion of FDNY responses in this dataset correspond to the most common type of incident?\n",
    "# double checking to make sure that the counts are correct:\n",
    "sum(df.INCIDENT_TYPE_DESC==df.INCIDENT_TYPE_DESC[2])\n",
    "df.INCIDENT_TYPE_DESC.size\n",
    "823378/2277779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q2: How many times more likely is an incident in Staten Island a false call compared to in Manhattan?\n",
    "# Definition of a false call: A false call is an incident for which 'INCIDENT_TYPE_DESC' is \n",
    "# '710 - Malicious, mischievous false call, other'.\n",
    "# 1. separate by location, use borough column\n",
    "boroughs = df.BOROUGH_DESC.unique()\n",
    "# staten mask\n",
    "staten = df.BOROUGH_DESC == boroughs[4]\n",
    "# manhattan mask\n",
    "manhattan = df.BOROUGH_DESC == boroughs[1]\n",
    "# use the masks to count '710 - Malicious, mischievous false call, other' for each location\n",
    "sfalse = sum(df[staten].INCIDENT_TYPE_DESC == '710 - Malicious, mischievous false call, other')\n",
    "mfalse = sum(df[manhattan].INCIDENT_TYPE_DESC == '710 - Malicious, mischievous false call, other')\n",
    "sfalse/mfalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q3.1: Compute what proportion of all incidents are cooking fires for every hour of the day by normalizing the \n",
    "# number of cooking fires in a given hour by the total number of incidents that occured in that hour.\n",
    "# Definition of a cooking fire: 'INCIDENT_TYPE_DESC' is '113 - Cooking fire, confined to container'\n",
    "# Note: round incident times down.\n",
    "# 1. cooking fire mask\n",
    "cooking = df.INCIDENT_TYPE_DESC == '113 - Cooking fire, confined to container'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. get # of incidents for every hour\n",
    "# convert str to datetime\n",
    "ts = pd.to_datetime(df.INCIDENT_DATE_TIME, format='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# round down to the nearest hour\n",
    "ts = ts.dt.floor('H')\n",
    "# count total number of incidents for every hour (index is the date time)\n",
    "tscounts = ts.value_counts()\n",
    "# get all of the unique date hours\n",
    "tsu = ts.unique()\n",
    "# tscounts[tscounts.index==ts[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. get # of cooking fire incidents for every hour\n",
    "# get date and time for all cooking fires\n",
    "ctime = df[cooking].INCIDENT_DATE_TIME\n",
    "# convert str to datetime\n",
    "ctime = pd.to_datetime(ctime, format='%m/%d/%Y %I:%M:%S %p')\n",
    "# round down to the nearest hour\n",
    "ctime = ctime.dt.floor('H')\n",
    "# count total number of incidents for every hour (index is the date time)\n",
    "ccount = ctime.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize cooking fire by the total number of incidents\n",
    "# merge by index (date time, common to both)\n",
    "tscounts = tscounts.rename('total_count')\n",
    "ccount = ccount.rename('cooking_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join into a dataframe\n",
    "incidents = pd.DataFrame(tscounts).join(ccount)\n",
    "# nans to 0\n",
    "incidents = incidents.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q3.2: Find the hour of the day that has the highest proportion of cooking fires and submit that proportion of \n",
    "# cooking fires.\n",
    "ratios = incidents.cooking_count/incidents.total_count\n",
    "ratios.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08789046762106846"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4: What is the ratio of the average number of units that arrive to a scene of an incident classified as\n",
    "# '111 - Building fire' to the number that arrive for '651 - Smoke scare, odor of smoke'?\n",
    "\n",
    "# 1. get the average number incidents '111 - Building fire'\n",
    "bfavg = (df.INCIDENT_TYPE_DESC == '111 - Building fire').sum()/df.shape[0]\n",
    "# 2. get the average number of incidents '651 - Smoke scare, odor of smoke'\n",
    "ssavg = (df.INCIDENT_TYPE_DESC == '651 - Smoke scare, odor of smoke').sum()/df.shape[0]\n",
    "# 3. get the ratio of building fire avg to smoke scare avg\n",
    "bfavg/ssavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q5.1: Check the distribution of the number of minutes it takes between the time a '111 - Building fire' incident\n",
    "# has been logged into the Computer Aided Dispatch system and the time at which the first unit arrives on scene.\n",
    "\n",
    "bfidx = df.INCIDENT_TYPE_DESC == '111 - Building fire'\n",
    "bftimes = df[bfidx][['INCIDENT_DATE_TIME', 'ARRIVAL_DATE_TIME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert str to datetime\n",
    "bftimes.INCIDENT_DATE_TIME = pd.to_datetime(bftimes.INCIDENT_DATE_TIME, format='%m/%d/%Y %I:%M:%S %p')\n",
    "bftimes.ARRIVAL_DATE_TIME = pd.to_datetime(bftimes.ARRIVAL_DATE_TIME, format='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the difference between the two times\n",
    "difftime = bftimes.ARRIVAL_DATE_TIME - bftimes.INCIDENT_DATE_TIME\n",
    "# convert to seconds\n",
    "difftime = difftime.dt.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.15\n",
      "4.15\n"
     ]
    }
   ],
   "source": [
    "# Q5.2: What is the third quartile of that distribution. Note: the number of minutes can be fractional\n",
    "# (ie, do not round).\n",
    "# there are nans\n",
    "print(difftime.quantile(0.75)/60)\n",
    "# remove nans\n",
    "print(difftime.dropna().quantile(0.75)/60)\n",
    "# np.percentile(difftime.dropna(), 75)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q6: What is the coefficient of determination (R squared) between the number of residents at each zip code and the\n",
    "# number of inicidents whose type is classified as '111 - Building fire' at each of those zip codes.\n",
    "# 1. calculate the number of building fire incidents at each zip code\n",
    "bfidx = df.INCIDENT_TYPE_DESC == '111 - Building fire'\n",
    "zipbf = df[bfidx]['ZIP_CODE']\n",
    "zipcounts = zipbf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert zip codes from string to int\n",
    "# then merge with census data\n",
    "zipcounts.index = zipcounts.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. load in the census data\n",
    "census = pd.read_csv('2010+Census+Population+By+Zipcode+(ZCTA).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join zip counts to census data\n",
    "census = census.join(zipcounts, on='Zip Code ZCTA')\n",
    "census = census.dropna()\n",
    "census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# x = number of residents\n",
    "x = census['2010 Census Population']\n",
    "# y = number of incidents\n",
    "y = census['ZIP_CODE']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.5973393948657464\n"
     ]
    }
   ],
   "source": [
    "# Q6: calculate r^2\n",
    "print(\"r-squared:\", r_value**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q7.1: For this question, only consider incidents that have information about whether a CO detector was present or\n",
    "# not.\n",
    "cotf = df[~pd.isnull(df['CO_DETECTOR_PRESENT_DESC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q7.2: compute the proportion of incidents that lasted 20-30, 30-40, 40-50, 50-60, and 60-70 minutes (both interval\n",
    "# boundary values included) by dividing the number of incidents in each time interval with the total number of\n",
    "# incidents.\n",
    "cotf = cotf[['TOTAL_INCIDENT_DURATION', 'CO_DETECTOR_PRESENT_DESC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# must include both edges, so I can't use pd.cut or np.digitize or histogram...\n",
    "def countinrange(x, y, b):\n",
    "        idx = (x >= b[0])&(x <=b [1])\n",
    "        return [idx.sum(), (y[idx]=='Yes').sum(), (y[idx]=='No').sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bin total incident duration into 20-30, 30-40, 40-50, 50-60, and 60-70 minutes\n",
    "# total incident duration is in seconds\n",
    "binranges = np.array([(20, 30), (30, 40), (40, 50), (50, 60), (60, 70)])*60\n",
    "# for each bin, count the total number of incidents in the time range, and the number of events with and without CO\n",
    "# detector\n",
    "bincounts = np.zeros([5, 3])\n",
    "c = 0\n",
    "# c1: total count, c2: CO detector present, c3: CO detector absent\n",
    "for bins in binranges:\n",
    "    bincounts[c] = countinrange(cotf.TOTAL_INCIDENT_DURATION, cotf.CO_DETECTOR_PRESENT_DESC, bins)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7682. 6501. 1181.]\n",
      " [2741. 2155.  586.]\n",
      " [1276.  926.  350.]\n",
      " [ 730.  481.  249.]\n",
      " [ 393.  235.  158.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5991265 , 0.2137732 , 0.09951646, 0.0569334 , 0.03065044])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the proportion of incidents in each bin\n",
    "print(bincounts)\n",
    "freqbin = bincounts[:,0]/bincounts[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18166436, 0.27192575, 0.37796976, 0.51767152, 0.67234043])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7.3: For each bin, compute the ratio of the 'CO detector absent' frequency to the 'CO detector present' frequency.\n",
    "coapr = bincounts[:, 2]/bincounts[:, 1]\n",
    "coapr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q7.4: Perform a linear regression of this ratio to the mid-point of the bins.\n",
    "midpoint = np.array([25, 35, 45, 55, 65])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(midpoint, coapr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33068849004143824"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7.5: From this, what is the predicted ratio for events lasting 39 minutes?\n",
    "predratio = slope*39 + intercept\n",
    "predratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17001180637544275"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8: Calculate the chi-square test statistic for testing whether an incident is more likely to last longer than \n",
    "# 60 minutes when CO detector is not present.\n",
    "# hypothesis: incident lasts longer than 60 min when CO detector is not present vs CO detector is present\n",
    "# filter out for all incidents > 60 min\n",
    "cotfgt60 = cotf[cotf.TOTAL_INCIDENT_DURATION > (60*60)]\n",
    "n = cotfgt60.shape[0] # total number of incidents > 60 min\n",
    "o = (cotfgt60.CO_DETECTOR_PRESENT_DESC=='No').sum() # number of incidents without CO detector\n",
    "e = n/2 # equal chance of CO detector present or not\n",
    "x2 = (o - e)**2/e\n",
    "x2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
